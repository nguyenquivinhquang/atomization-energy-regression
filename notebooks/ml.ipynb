{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e:\\python\\atomization-energy-regression\n"
     ]
    }
   ],
   "source": [
    "%cd ../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data_processing.molecule import get_molecule_name \n",
    "import scipy.io\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = scipy.io.loadmat('dataset\\qm7.mat')\n",
    "X = data['X'] # Coulomb matrices -> 7165 x 23 x 23\n",
    "T = data['T'].T.squeeze() # atomization energies Y -> 7165 x 1\n",
    "Z = data['Z'] # atomic charge -> 7165 x 23\n",
    "R = data['R'] # cartesian coordinates -> 7165 x 23 x 3\n",
    "data_train, data_test = {}, {}\n",
    "molecule_name = get_molecule_name(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.        +0.j        ,  0.        +0.j        ,\n",
       "        0.        +0.j        ,  0.        +0.j        ,\n",
       "        0.        +0.j        , 11.350574  +0.j        ,\n",
       "       -2.685962  +0.j        ,  2.1595643 +0.j        ,\n",
       "       -1.3413086 +0.j        ,  0.9704444 +0.j        ,\n",
       "        0.25353876+0.j        ,  0.16964687+0.20988576j,\n",
       "        0.16964687-0.20988576j, -0.2560594 +0.13355258j,\n",
       "       -0.2560594 -0.13355258j, -0.2869199 +0.j        ,\n",
       "       -0.06175096+0.21241368j, -0.06175096-0.21241368j,\n",
       "        0.        +0.j        ,  0.        +0.j        ,\n",
       "        0.        +0.j        ,  0.        +0.j        ,\n",
       "        0.        +0.j        ], dtype=complex64)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v =data['X'][5577]\n",
    "np.linalg.norm(v, axis=1)\n",
    "idx = np.argsort(np.linalg.norm(v, axis=1))\n",
    "v = v[idx,:]\n",
    "np.linalg.eigvals(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_engineer(data):\n",
    "    X = data['X'] # Coulomb matrices -> 7165 x 23 x 23\n",
    "    T = data['T'].T.squeeze() # atomization energies Y -> 7165 x 1\n",
    "    Z = data['Z'] # atomic charge -> 7165 x 23\n",
    "    R = data['R'] # cartesian coordinates -> 7165 x 23 x 3\n",
    "    data_train, data_test = {}, {}\n",
    "    molecule_name = get_molecule_name(data)\n",
    "    \n",
    "    \n",
    "    y = np.transpose(T)\n",
    "    y_scaling_factor = np.max(np.absolute(y))\n",
    "    y_scaled = y/y_scaling_factor\n",
    "   \n",
    "    features_vector = []\n",
    "    for (x,z,r) in zip(X,Z,R):\n",
    "        sorted_idx = np.argsort(np.linalg.norm(x, axis=1)) \n",
    "        sorted_coulomb_mat = x[sorted_idx, :]  # Sort rows\n",
    "        sorted_coulomb_mat.sort(axis=1)\n",
    "        order_x = sorted_coulomb_mat\n",
    "        features_vector.append(np.concatenate((np.linalg.eigvals(x), list(nx.degree_centrality(nx.from_numpy_matrix(x)).values()), order_x.flatten(),z, r.mean(axis=0), r.std(axis=0))))\n",
    "        # print(features_vector[-1].shape)\n",
    "    return features_vector, y_scaled, y_scaling_factor\n",
    "\n",
    "X, Y, min_max_scaler  = feature_engineer(data)\n",
    "X = np.asarray(X)\n",
    "Y = np.asarray(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(575,)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.002145205311624165\n",
      "0.0022841842393681454\n",
      "0.0021534784768279113\n",
      "0.002244288384315195\n",
      "0.0022152076449769207\n",
      "4.840972402638049\n"
     ]
    }
   ],
   "source": [
    "def cross_validation(X, y, model, splits):\n",
    "    mae = []\n",
    "    for (idx, split) in enumerate(splits):\n",
    "        mask = np.zeros(y.size, dtype=bool)\n",
    "        mask[split] = True\n",
    "        X_train = X[~mask]\n",
    "        y_train = y[~mask]\n",
    "        X_test = X[mask]\n",
    "        y_test = y[mask]\n",
    "        \n",
    "        \n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        mae.append(mean_absolute_error(y_pred, y_test))\n",
    "        print(mae[-1])\n",
    "    return mae\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "krr_model = KernelRidge(alpha = 0.0001, kernel = \"rbf\", gamma=0.0001)\n",
    "\n",
    "\n",
    "\n",
    "mae = cross_validation(X, Y, krr_model, data['P'])\n",
    "mae = [x * min_max_scaler for x in mae]\n",
    "print(np.mean(mae))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "7.828280902462109"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.002358472093598374\n",
      "0.0024254944526359685\n",
      "0.002316148727643307\n",
      "0.002479579484810037\n",
      "0.002495159201691131\n",
      "5.293615976230074\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectKBest, f_classif, f_regression, mutual_info_regression\n",
    "X_new = SelectKBest(f_regression, k=550).fit_transform(X, Y)\n",
    "mae = cross_validation(X_new, Y, krr_model, data['P'])\n",
    "mae = [x * min_max_scaler for x in mae]\n",
    "print(np.mean(mae))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7165, 200)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0028786168777998828\n",
      "0.0029050120220716416\n",
      "0.0027755819021060913\n",
      "0.0030067621560669567\n",
      "0.002783547730923894\n",
      "6.290829870043775\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "svr_model = SVR(kernel='rbf', gamma=1e-4, epsilon=1e-6)\n",
    "\n",
    "\n",
    "mae = cross_validation(X, Y, svr_model, data['P'])\n",
    "mae = [x * min_max_scaler for x in mae]\n",
    "print(np.mean(mae))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import DotProduct, WhiteKernel\n",
    "kernel = DotProduct() + WhiteKernel()\n",
    "gpr_model = GaussianProcessRegressor(kernel=kernel, random_state=0)\n",
    "mae = cross_validation(X, Y, gpr_model, data['P'])\n",
    "mae = [x * min_max_scaler for x in mae]\n",
    "print(np.mean(mae))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.005196275938669"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KernelRidge(alpha=0.0001, coef0=1, degree=3, gamma=0.0001, kernel='rbf',\n",
       "            kernel_params=None)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "krr_model.fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9999845458858015"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "krr_model.score(X, Y )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'X'"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "V = {\n",
    "    'X':1,\n",
    "    'Y':2,\n",
    "    'Z': 3\n",
    "}\n",
    "t1, t2, y3 = V\n",
    "t1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chem",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
